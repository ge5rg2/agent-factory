from google import genai
import os
import ast
import json
import re
import subprocess
from dotenv import load_dotenv

load_dotenv()
client = genai.Client(
    api_key=os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
)

MAX_FIX_ITERATIONS = 2


# â”€â”€ íŒŒì¼ íƒ€ì…ë³„ ì •ì  ê²€ì‚¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _check_python(file_path: str, code: str) -> list:
    """AST íŒŒì‹±ìœ¼ë¡œ Python ë¬¸ë²• ì˜¤ë¥˜ ê²€ì‚¬."""
    try:
        ast.parse(code)
        return []
    except SyntaxError as e:
        return [f"[{file_path}] SyntaxError line {e.lineno}: {e.msg}"]


def _check_js(file_path: str, full_path: str) -> list:
    """node --check ë¡œ JS ë¬¸ë²• ì˜¤ë¥˜ ê²€ì‚¬. nodeê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€."""
    try:
        result = subprocess.run(
            ["node", "--check", full_path],
            capture_output=True, text=True, timeout=10
        )
        if result.returncode != 0:
            return [f"[{file_path}] JS Error: {result.stderr.strip()}"]
        return []
    except FileNotFoundError:
        return []  # node ë¯¸ì„¤ì¹˜ í™˜ê²½ì€ ê±´ë„ˆëœ€
    except subprocess.TimeoutExpired:
        return [f"[{file_path}] JS check timed out"]


def _check_html(file_path: str, code: str) -> list:
    """í•„ìˆ˜ HTML êµ¬ì¡° íƒœê·¸ ì¡´ì¬ ì—¬ë¶€ ê²€ì‚¬."""
    errors = []
    lower = code.lower()
    for tag in ("<html", "<head", "<body"):
        if tag not in lower:
            errors.append(f"[{file_path}] HTML: '{tag}>' íƒœê·¸ ëˆ„ë½")
    return errors


def _run_syntax_checks(output_dir: str, codes: dict) -> list:
    """output ë””ë ‰í† ë¦¬ì˜ ì‹¤ì œ íŒŒì¼ì„ ëŒ€ìƒìœ¼ë¡œ ëª¨ë“  ì •ì  ê²€ì‚¬ ì‹¤í–‰."""
    errors = []
    for file_path in codes:
        full_path = os.path.join(output_dir, file_path)
        if not os.path.exists(full_path):
            continue
        with open(full_path, encoding="utf-8") as f:
            code = f.read()

        if file_path.endswith(".py"):
            errors.extend(_check_python(file_path, code))
        elif file_path.endswith(".js"):
            errors.extend(_check_js(file_path, full_path))
        elif file_path.endswith(".html"):
            errors.extend(_check_html(file_path, code))
    return errors


# â”€â”€ requirements.txt ìœ íš¨ì„± ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# PyPI íŒ¨í‚¤ì§€ëª…(ì†Œë¬¸ìÂ·ì–¸ë”ìŠ¤ì½”ì–´ ì •ê·œí™”) â†’ ì½”ë“œ ë‚´ import ì‹œ ì‚¬ìš©í•˜ëŠ” ìµœìƒìœ„ ëª¨ë“ˆëª…
_PYPI_TO_IMPORT: dict = {
    "fastapi":                   "fastapi",
    "uvicorn":                   "uvicorn",
    "starlette":                 "starlette",
    "pydantic":                  "pydantic",
    "sqlalchemy":                "sqlalchemy",
    "alembic":                   "alembic",
    "websockets":                "websockets",
    "python_multipart":          "multipart",
    "aiofiles":                  "aiofiles",
    "httpx":                     "httpx",
    "requests":                  "requests",
    "python_dotenv":             "dotenv",
    "python_jose":               "jose",
    "passlib":                   "passlib",
    "pillow":                    "PIL",
    "bcrypt":                    "bcrypt",
    "cryptography":              "cryptography",
    "itsdangerous":              "itsdangerous",
    "jinja2":                    "jinja2",
    "aiosqlite":                 "aiosqlite",
    "asyncpg":                   "asyncpg",
    "psycopg2":                  "psycopg2",
    "psycopg2_binary":           "psycopg2",
    "pymysql":                   "pymysql",
    "motor":                     "motor",
    "pymongo":                   "pymongo",
    "redis":                     "redis",
    "celery":                    "celery",
    "boto3":                     "boto3",
    "openai":                    "openai",
    "anthropic":                 "anthropic",
    "google_genai":              "google",
    "google_generativeai":       "google",
    "numpy":                     "numpy",
    "pandas":                    "pandas",
    "scipy":                     "scipy",
    "matplotlib":                "matplotlib",
    "scikit_learn":              "sklearn",
    "torch":                     "torch",
    "tensorflow":                "tensorflow",
    "pytest":                    "pytest",
    "pytest_asyncio":            "pytest_asyncio",
    "httpx":                     "httpx",
    "anyio":                     "anyio",
    "email_validator":           "email_validator",
    "python_slugify":            "slugify",
    "pyyaml":                    "yaml",
    "toml":                      "toml",
    "click":                     "click",
    "rich":                      "rich",
    "loguru":                    "loguru",
}


def _normalize_pkg_name(raw: str) -> str:
    """PyPI íŒ¨í‚¤ì§€ëª…ì„ ì†Œë¬¸ì ì–¸ë”ìŠ¤ì½”ì–´ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”."""
    # extras ì œê±°: uvicorn[standard] â†’ uvicorn
    name = re.split(r'[\[>=<!;\s]', raw.strip())[0]
    return name.lower().replace("-", "_")


def _collect_imported_top_modules(codes: dict) -> set:
    """ìƒì„±ëœ Python íŒŒì¼ì—ì„œ ì‹¤ì œë¡œ importëœ ìµœìƒìœ„ ëª¨ë“ˆëª… ìˆ˜ì§‘."""
    top_modules: set = set()
    for file_path, code in codes.items():
        if not file_path.endswith(".py"):
            continue
        for line in code.splitlines():
            line = line.strip()
            # `import X` / `import X.Y`
            m = re.match(r'^import\s+([\w.]+)', line)
            if m:
                top_modules.add(m.group(1).split(".")[0])
            # `from X import Y` / `from X.Y import Z`
            m2 = re.match(r'^from\s+([\w.]+)\s+import', line)
            if m2:
                top_modules.add(m2.group(1).split(".")[0])
    return top_modules


# import ì—†ì´ë„ ì‹¤í–‰ì— í•„ìˆ˜ì¸ ì¸í”„ë¼ íŒ¨í‚¤ì§€ (í•­ìƒ ìœ ì§€)
_ALWAYS_KEEP_NORMALIZED: set = {
    "uvicorn",      # ASGI ì„œë²„ (CLIë¡œ ì‹¤í–‰, ì½”ë“œì— import ì•ˆ í•¨)
    "gunicorn",     # WSGI/ASGI ì„œë²„ (CLI)
    "hypercorn",    # ASGI ì„œë²„ (CLI)
    "daphne",       # ASGI ì„œë²„ (CLI)
}

# ëª…ì‹œì  import ëŒ€ì‹  ì½”ë“œ ë‚´ íŠ¹ì • ì‹ë³„ì ì¶œí˜„ìœ¼ë¡œ í•„ìš” ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” íŒ¨í‚¤ì§€
# key: ì •ê·œí™”ëœ PyPIëª…, value: ì½”ë“œ ì „ì²´ì—ì„œ ê²€ìƒ‰í•  ì •ê·œì‹ íŒ¨í„´
_PYPI_TO_CODE_PATTERN: dict = {
    "websockets":       r'\bWebSocket\b',            # FastAPI WebSocket ê¸°ëŠ¥ì´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©
    "python_multipart": r'\b(Form|File|UploadFile)\b',  # FastAPI íŒŒì¼Â·í¼ ì—…ë¡œë“œ
}


def _fix_requirements_txt(output_dir: str, codes: dict) -> list:
    """requirements.txtì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•Šê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒ¨í‚¤ì§€ë¥¼ ì œê±°.

    ì „ëµ:
      1. ìƒì„±ëœ Python íŒŒì¼ì˜ import ë¬¸ì—ì„œ ì‹¤ì œ ì‚¬ìš© ëª¨ë“ˆëª… ìˆ˜ì§‘
      2. _ALWAYS_KEEP_NORMALIZED ì— ì†í•˜ë©´ ë¬´ì¡°ê±´ ìœ ì§€ (uvicorn ë“± CLI ì„œë²„)
      3. _PYPI_TO_IMPORT ë§¤í•‘í‘œì— ìˆìœ¼ë©´ â†’ í•´ë‹¹ importëª…ì´ ì½”ë“œì— ìˆì„ ë•Œë§Œ ìœ ì§€
      4. ë§¤í•‘í‘œì— ì—†ìœ¼ë©´ â†’ pkg ì´ë¦„ ìì²´ê°€ importì— ë³´ì´ë©´ ìœ ì§€, ê·¸ ì™¸ ì œê±°
    """
    req_key = "requirements.txt"
    if req_key not in codes:
        return []

    imported = _collect_imported_top_modules(codes)

    # ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰ìš©: ëª¨ë“  Python íŒŒì¼ ë‚´ìš©ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
    all_py_code = "\n".join(v for k, v in codes.items() if k.endswith(".py"))

    req_lines = codes[req_key].splitlines()
    new_lines: list = []
    removed: list = []

    for line in req_lines:
        stripped = line.strip()
        # ë¹ˆ ì¤„Â·ì£¼ì„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        if not stripped or stripped.startswith("#"):
            new_lines.append(line)
            continue

        pkg_norm = _normalize_pkg_name(stripped)

        # â‘  í•­ìƒ ìœ ì§€ ëª©ë¡ (ì„œë²„ CLI íŒ¨í‚¤ì§€)
        if pkg_norm in _ALWAYS_KEEP_NORMALIZED:
            new_lines.append(line)
            continue

        # â‘¡ ì½”ë“œ íŒ¨í„´ìœ¼ë¡œ í•„ìš” ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” íŒ¨í‚¤ì§€ (e.g. websockets, python-multipart)
        code_pattern = _PYPI_TO_CODE_PATTERN.get(pkg_norm)
        if code_pattern is not None:
            if re.search(code_pattern, all_py_code):
                new_lines.append(line)    # íŒ¨í„´ ë°œê²¬ â†’ ìœ ì§€
            else:
                removed.append(stripped)  # íŒ¨í„´ ì—†ìŒ â†’ ì œê±°
            continue

        # â‘¢ ì•Œë ¤ì§„ ë§¤í•‘í‘œì—ì„œ importëª… ì¡°íšŒ
        import_name = _PYPI_TO_IMPORT.get(pkg_norm)

        if import_name is not None:
            # ë§¤í•‘í‘œì— ìˆëŠ” íŒ¨í‚¤ì§€ â†’ import ë¬¸ì—ì„œ ì‹¤ì œ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
            if import_name in imported:
                new_lines.append(line)    # ì‚¬ìš©ë¨ â†’ ìœ ì§€
            else:
                removed.append(stripped)  # ë¯¸ì‚¬ìš© â†’ ì œê±°
        else:
            # â‘£ ë§¤í•‘í‘œ ë¯¸ë“±ë¡ íŒ¨í‚¤ì§€ â†’ pkg ì´ë¦„ ìì²´ê°€ importì— ë³´ì´ë©´ ìœ ì§€
            pkg_base = pkg_norm.split("_")[0]  # e.g. psycopg2_binary â†’ psycopg2
            if pkg_norm in imported or pkg_base in imported:
                new_lines.append(line)    # ìœ ì§€
            else:
                removed.append(stripped)  # ì•Œ ìˆ˜ ì—†ê³  ë¯¸ì‚¬ìš© â†’ ì œê±°

    if not removed:
        return []

    new_content = "\n".join(new_lines)
    codes[req_key] = new_content
    full_path = os.path.join(output_dir, req_key)
    if os.path.exists(full_path):
        with open(full_path, "w", encoding="utf-8") as f:
            f.write(new_content)
    return removed


# â”€â”€ Python import ê²½ë¡œ ì‚¬ì „ ë³´ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _fix_python_imports(output_dir: str, codes: dict) -> list:
    """ëª¨ë“  intra-project importë¥¼ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  __init__.pyë¥¼ ìë™ ìƒì„±.

    ì²˜ë¦¬ íŒ¨í„´:
      bare:     `from models import X`    â†’ `from backend.models import X`
      relative: `from .models import X`   â†’ `from backend.api.v1.endpoints.models import X` (í•´ì„ í›„ ì˜¬ë°”ë¥¸ ì ˆëŒ€ê²½ë¡œ)
      wrong depth: `from ...models import X` â†’ `from backend.models import X`
      pkg rel:  `from . import endpoints` â†’ `from backend.api.v1 import endpoints`
    """
    fixed = []

    # 1. name â†’ absolute dotted path ë§µ êµ¬ì„± (ëª¨ë“ˆ + íŒ¨í‚¤ì§€ ëª¨ë‘)
    name_to_abs: dict = {}

    # ëª¨ë“  ë””ë ‰í† ë¦¬ ê²½ë¡œ ìˆ˜ì§‘ (íŒ¨í‚¤ì§€ ì¶”ì ìš©)
    all_dirs: set = set()
    for file_path in codes:
        normalized = file_path.replace("\\", "/")
        if "/" in normalized:
            parts = normalized.split("/")
            for i in range(1, len(parts)):
                all_dirs.add("/".join(parts[:i]))

    # íŒ¨í‚¤ì§€(ë””ë ‰í† ë¦¬) ë“±ë¡ â€” ë¨¼ì € ì¶”ê°€í•´ì„œ ëª¨ë“ˆì´ ê°™ì€ ì´ë¦„ì´ë©´ ëª¨ë“ˆì´ ë®ì–´ì”€
    for dir_path in sorted(all_dirs):
        pkg_name = dir_path.split("/")[-1]
        abs_dotted = dir_path.replace("/", ".")
        if pkg_name not in name_to_abs:
            name_to_abs[pkg_name] = abs_dotted

    # ëª¨ë“ˆ(.py íŒŒì¼) ë“±ë¡ â€” ê°™ì€ ì´ë¦„ì´ë©´ ëª¨ë“ˆì´ íŒ¨í‚¤ì§€ë¥¼ ë®ì–´ì”€
    for file_path in codes:
        if not file_path.endswith(".py"):
            continue
        module_name = os.path.splitext(os.path.basename(file_path))[0]
        if module_name == "__init__":
            continue
        abs_dotted = file_path.replace("\\", "/").replace("/", ".")[:-3]
        name_to_abs[module_name] = abs_dotted

    # 2. ëª¨ë“  ì¤‘ê°„ ë””ë ‰í† ë¦¬ì— __init__.py ìë™ ìƒì„±
    for dir_path in sorted(all_dirs):
        init_path = f"{dir_path}/__init__.py"
        full_init = os.path.join(output_dir, init_path)
        if not os.path.exists(full_init):
            os.makedirs(os.path.dirname(full_init), exist_ok=True)
            with open(full_init, "w", encoding="utf-8") as f:
                f.write("")
            if init_path not in codes:
                codes[init_path] = ""
            fixed.append(f"{init_path} (ì‹ ê·œ ìƒì„±)")

    # 3. ê° Python íŒŒì¼ì˜ import êµ¬ë¬¸ ì ˆëŒ€ê²½ë¡œë¡œ ë³´ì •
    for file_path in list(codes.keys()):
        if not file_path.endswith(".py") or "/" not in file_path:
            continue

        code = codes[file_path]
        new_lines = []
        changed = False

        # í˜„ì¬ íŒŒì¼ ë””ë ‰í† ë¦¬ì˜ ì ˆëŒ€ dotted path (ìƒëŒ€ import í•´ì„ìš©)
        dir_abs = os.path.dirname(file_path).replace("\\", "/").replace("/", ".")
        dir_parts = dir_abs.split(".") if dir_abs else []

        for line in code.splitlines():

            # â”€â”€ Case 1: ì (dot) í¬í•¨ ìƒëŒ€ import â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # íŒ¨í„´ A: `from .X import Y`  (dots ë°”ë¡œ ë’¤ì— ëª¨ë“ˆ/íŒ¨í‚¤ì§€ëª…)
            m_rel = re.match(r'^(\s*from\s+)(\.+)(\w+)(\s+import\s+.+)$', line)
            if m_rel:
                dots = m_rel.group(2)
                target_name = m_rel.group(3)
                import_tail = m_rel.group(4)
                dot_count = len(dots)
                levels_up = dot_count - 1

                if target_name in name_to_abs:
                    # ì•Œë ¤ì§„ í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“ˆ/íŒ¨í‚¤ì§€ â†’ ì ˆëŒ€ê²½ë¡œë¡œ êµì²´
                    new_line = f"from {name_to_abs[target_name]}{import_tail}"
                else:
                    # ë¯¸ë“±ë¡ ì´ë¦„ â†’ dot ê°œìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì ˆëŒ€ê²½ë¡œ ê³„ì‚°ë§Œ ìˆ˜í–‰
                    if levels_up == 0:
                        base_parts = dir_parts
                    elif levels_up < len(dir_parts):
                        base_parts = dir_parts[:-levels_up]
                    else:
                        base_parts = []
                    abs_target = ".".join(base_parts + [target_name]) if base_parts else target_name
                    new_line = f"from {abs_target}{import_tail}"

                new_lines.append(new_line)
                if new_line.strip() != line.strip():
                    changed = True
                continue

            # íŒ¨í„´ B: `from . import X`  (dots ë’¤ì— ëª¨ë“ˆëª… ì—†ì´ ë°”ë¡œ import)
            m_rel_pkg = re.match(r'^(\s*from\s+)(\.+)(\s+import\s+.+)$', line)
            if m_rel_pkg:
                dots = m_rel_pkg.group(2)
                import_tail = m_rel_pkg.group(3)
                dot_count = len(dots)
                levels_up = dot_count - 1

                if levels_up == 0:
                    base_pkg = dir_abs
                elif levels_up < len(dir_parts):
                    base_pkg = ".".join(dir_parts[:-levels_up])
                else:
                    base_pkg = ""

                if base_pkg:
                    new_line = f"from {base_pkg}{import_tail}"
                else:
                    new_line = line  # í•´ì„ ë¶ˆê°€, ê·¸ëŒ€ë¡œ ìœ ì§€
                new_lines.append(new_line)
                if new_line.strip() != line.strip():
                    changed = True
                continue

            # â”€â”€ Case 2: bare `from X import Y` â†’ ì ˆëŒ€ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            m_bare = re.match(r'^(\s*from\s+)(\w+)(\s+import\s+.+)$', line)
            if m_bare and m_bare.group(2) in name_to_abs:
                target_name = m_bare.group(2)
                import_tail = m_bare.group(3)
                new_line = f"from {name_to_abs[target_name]}{import_tail}"
                new_lines.append(new_line)
                if new_line.strip() != line.strip():
                    changed = True
                continue

            # â”€â”€ Case 3: bare `import X` â†’ `from pkg import X` â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            m_bare_imp = re.match(r'^(\s*import\s+)(\w+)(.*)$', line)
            if m_bare_imp and m_bare_imp.group(2) in name_to_abs:
                target_name = m_bare_imp.group(2)
                abs_path = name_to_abs[target_name]
                pkg_parts = abs_path.split(".")
                if len(pkg_parts) > 1:
                    pkg = ".".join(pkg_parts[:-1])
                    new_line = f"from {pkg} import {target_name}{m_bare_imp.group(3)}"
                else:
                    new_line = line  # ìµœìƒìœ„ ëª¨ë“ˆì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                new_lines.append(new_line)
                if new_line.strip() != line.strip():
                    changed = True
                continue

            new_lines.append(line)

        if changed:
            new_code = "\n".join(new_lines)
            codes[file_path] = new_code
            full_path = os.path.join(output_dir, file_path)
            if os.path.exists(full_path):
                with open(full_path, "w", encoding="utf-8") as f:
                    f.write(new_code)
            fixed.append(file_path)

    return fixed


# â”€â”€ Gemini ì½”ë“œ ë¦¬ë·° & ìˆ˜ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _gemini_review_and_fix(prd: str, current_codes: dict, syntax_errors: list) -> dict:
    """ì „ì²´ ì½”ë“œë² ì´ìŠ¤ë¥¼ Geminië¡œ ë¦¬ë·°í•˜ê³ , ì´ìŠˆì™€ ìˆ˜ì • ì½”ë“œ ë°˜í™˜."""
    files_block = "\n".join(
        f"\n--- {path} ---\n{code}" for path, code in current_codes.items()
    )
    errors_block = (
        "\n=== ì •ì  ê²€ì‚¬ì—ì„œ ë°œê²¬ëœ ì˜¤ë¥˜ ===\n" + "\n".join(syntax_errors)
        if syntax_errors else ""
    )

    prompt = f"""
ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì½”ë“œ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤.
ì•„ë˜ ì½”ë“œë² ì´ìŠ¤ë¥¼ ê²€í† í•˜ê³  ë¬¸ì œë¥¼ ë°œê²¬í•˜ë©´ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

=== ê¸°íšì„œ (PRD) ===
{prd}
{errors_block}

=== ì „ì²´ ì½”ë“œë² ì´ìŠ¤ ===
{files_block}

ê²€í†  í•­ëª©:
1. ë¬¸ë²• ì˜¤ë¥˜ ë° ëŸ°íƒ€ì„ ì—ëŸ¬ ê°€ëŠ¥ì„±
2. import ëˆ„ë½ ë˜ëŠ” ì˜ëª»ëœ ê²½ë¡œ
   - [ì¤‘ìš”] ë°˜ë“œì‹œ ì ˆëŒ€ê²½ë¡œ import ì‚¬ìš© (`from backend.models import X` í˜•ì‹)
   - ìƒëŒ€ê²½ë¡œ import (from .X, from ..X, from ...X) ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
   - bare import (from models import X) ë„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. í”„ë¡ íŠ¸ì—”ë“œ-ë°±ì—”ë“œ API ì—°ë™ ë¶ˆì¼ì¹˜ (URL, ë©”ì„œë“œ, í•„ë“œëª…)
4. ê¸°íšì„œ ëŒ€ë¹„ í•µì‹¬ ê¸°ëŠ¥ ëˆ„ë½

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ):
{{
    "issues": ["ë°œê²¬ëœ ë¬¸ì œ ì„¤ëª… 1", "ë°œê²¬ëœ ë¬¸ì œ ì„¤ëª… 2"],
    "fixed_files": {{
        "ìˆ˜ì •ì´_í•„ìš”í•œ_íŒŒì¼ê²½ë¡œ": "ìˆ˜ì •ëœ_ì „ì²´_ì½”ë“œ"
    }},
    "summary": "ì „ì²´ QC ê²°ê³¼ í•œ ì¤„ ìš”ì•½"
}}

ìˆ˜ì •ì´ í•„ìš” ì—†ëŠ” íŒŒì¼ì€ fixed_filesì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
ìˆ˜ì •í•  ë¬¸ì œê°€ ì „í˜€ ì—†ìœ¼ë©´ issuesë¥¼ ë¹ˆ ë°°ì—´ë¡œ, fixed_filesë¥¼ ë¹ˆ ê°ì²´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
"""

    response = client.models.generate_content(
        model='gemini-2.5-flash-lite',
        contents=prompt
    )
    raw = response.text.strip()
    if raw.startswith("```"):
        raw = re.sub(r'^```(?:json)?\n?', '', raw)
        raw = re.sub(r'\n?```$', '', raw.strip())
    return json.loads(raw)


# â”€â”€ README ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _generate_readme(state: dict, output_dir: str, codes: dict) -> None:
    """QC ì™„ë£Œ í›„ output ë””ë ‰í† ë¦¬ì— ì‹¤í–‰ë²•ì´ ë‹´ê¸´ README.md ìƒì„±."""

    file_tree_block = "\n".join(f"- {path}: {desc}" for path, desc in state.get("file_tree", {}).items())
    files_block = "\n".join(f"\n--- {path} ---\n{code}" for path, code in codes.items())

    prompt = f"""
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¬¸ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ í”„ë¡œì íŠ¸ë¥¼ ì²˜ìŒ ë³´ëŠ” ê°œë°œìê°€ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” README.mdë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

=== ê¸°íšì„œ (PRD) ===
{state.get("prd", "")}

=== íŒŒì¼ êµ¬ì¡° ===
{file_tree_block}

=== ì „ì²´ ì½”ë“œ ===
{files_block}

README.mdì— ë°˜ë“œì‹œ í¬í•¨í•  í•­ëª©:
1. í”„ë¡œì íŠ¸ ì œëª© ë° í•œ ì¤„ ì„¤ëª…
2. ê¸°ìˆ  ìŠ¤íƒ (ì–¸ì–´, í”„ë ˆì„ì›Œí¬, DB ë“±)
3. ë””ë ‰í† ë¦¬ êµ¬ì¡° (íŠ¸ë¦¬ í˜•íƒœ)
4. ì‚¬ì „ ìš”êµ¬ì‚¬í•­ (Python ë²„ì „, node ì—¬ë¶€ ë“±)
5. ì„¤ì¹˜ ë° ì‹¤í–‰ ë°©ë²•
   - ë°±ì—”ë“œ: ê°€ìƒí™˜ê²½ ìƒì„±, íŒ¨í‚¤ì§€ ì„¤ì¹˜(requirements ëª…ì‹œ), ì„œë²„ ì‹¤í–‰ ëª…ë ¹ì–´
   - í”„ë¡ íŠ¸ì—”ë“œ: ë³„ë„ ë¹Œë“œ ë¶ˆí•„ìš”í•œ ê²½ìš° ë¸Œë¼ìš°ì € ì—´ê¸° ë°©ë²•, ë˜ëŠ” serve ëª…ë ¹ì–´
6. ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸ (ìˆëŠ” ê²½ìš°)
7. ì‹¤í–‰ í™•ì¸ ë°©ë²• (ì ‘ì† URL ë“±)

ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. JSONì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
"""

    try:
        response = client.models.generate_content(
            model='gemini-2.5-flash-lite',
            contents=prompt
        )
        readme_content = response.text.strip()
        # í˜¹ì‹œ ```markdown ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì§„ ê²½ìš° ì œê±°
        if readme_content.startswith("```"):
            readme_content = re.sub(r'^```(?:markdown)?\n?', '', readme_content)
            readme_content = re.sub(r'\n?```$', '', readme_content.strip())

        readme_path = os.path.join(output_dir, "README.md")
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(readme_content)
        print(f"  ğŸ“„ README.md ìƒì„± ì™„ë£Œ â†’ {readme_path}")
    except Exception as e:
        print(f"  âš ï¸  README.md ìƒì„± ì‹¤íŒ¨: {e}")


# â”€â”€ QC Agent ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def qc_agent(state: dict) -> dict:
    output_dir = os.path.join("output", state["project_name"])
    codes = dict(state.get("codes", {}))
    prd = state.get("prd", "")

    if not codes:
        state.update({"feedback": "ê²€ì¦í•  ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.", "current_step": "ERROR"})
        return state

    # 0-a. requirements.txt ìœ íš¨ì„± ê²€ì¦ (ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¯¸ì‚¬ìš© íŒ¨í‚¤ì§€ ì œê±°)
    req_removed = _fix_requirements_txt(output_dir, codes)
    if req_removed:
        print(f"  ğŸ—‘ï¸  requirements.txt ìœ ë ¹ íŒ¨í‚¤ì§€ ì œê±° ({len(req_removed)}ê±´): {', '.join(req_removed)}")

    # 0-b. Python import ê²½ë¡œ ì‚¬ì „ ë³´ì • (ìƒëŒ€/bare â†’ ì ˆëŒ€ê²½ë¡œ, ì¤‘ê°„ __init__.py ìƒì„±)
    import_fixes = _fix_python_imports(output_dir, codes)
    if import_fixes:
        print(f"  ğŸ”§ Import ê²½ë¡œ ì‚¬ì „ ë³´ì • ({len(import_fixes)}ê±´): {', '.join(import_fixes)}")

    all_issues = []
    total_fixed_files = set()

    for iteration in range(1, MAX_FIX_ITERATIONS + 1):
        print(f"  ğŸ” QC ê²€ì¦ {iteration}íšŒì°¨...")

        # 1. output ë””ë ‰í† ë¦¬ì˜ ì‹¤ì œ íŒŒì¼ ë‚´ìš© ì½ê¸°
        current_codes = {}
        for file_path in codes:
            full_path = os.path.join(output_dir, file_path)
            if os.path.exists(full_path):
                with open(full_path, encoding="utf-8") as f:
                    current_codes[file_path] = f.read()

        # 2. ì •ì  ë¬¸ë²• ê²€ì‚¬
        syntax_errors = _run_syntax_checks(output_dir, codes)
        if syntax_errors:
            print(f"  âš ï¸  ë¬¸ë²• ì˜¤ë¥˜ {len(syntax_errors)}ê±´ ë°œê²¬")
            for err in syntax_errors:
                print(f"      {err}")
        else:
            print(f"  âœ… ë¬¸ë²• ê²€ì‚¬ í†µê³¼")

        # 3. Gemini ì½”ë“œ ë¦¬ë·°
        try:
            result = _gemini_review_and_fix(prd, current_codes, syntax_errors)
        except (json.JSONDecodeError, Exception) as e:
            print(f"  âš ï¸  Gemini ë¦¬ë·° íŒŒì‹± ì‹¤íŒ¨: {e}")
            break

        issues = result.get("issues", [])
        fixed_files = result.get("fixed_files", {})
        summary = result.get("summary", "")

        if issues:
            all_issues.extend(issues)
            print(f"  ğŸ“‹ ì´ìŠˆ {len(issues)}ê±´: {', '.join(issues[:2])}{'...' if len(issues) > 2 else ''}")

        # 4. ìˆ˜ì • íŒŒì¼ ì ìš©
        if fixed_files:
            print(f"  ğŸ”§ {len(fixed_files)}ê°œ íŒŒì¼ ìˆ˜ì • ì ìš© ì¤‘...")
            for file_path, fixed_code in fixed_files.items():
                full_path = os.path.join(output_dir, file_path)
                if os.path.exists(full_path):
                    with open(full_path, "w", encoding="utf-8") as f:
                        f.write(fixed_code)
                    codes[file_path] = fixed_code
                    total_fixed_files.add(file_path)
            print(f"  âœ… ìˆ˜ì • ì™„ë£Œ")
        else:
            print(f"  âœ… ì¶”ê°€ ìˆ˜ì • í•„ìš” ì—†ìŒ")
            # ì´ìŠˆë„ ì—†ê³  ìˆ˜ì •ë„ ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
            if not issues and not syntax_errors:
                print(f"\n  ğŸ“ README.md ìƒì„± ì¤‘...")
                _generate_readme(state, output_dir, codes)
                state.update({
                    "codes": codes,
                    "feedback": summary or "ëª¨ë“  íŒŒì¼ QC í†µê³¼",
                    "current_step": "DONE"
                })
                return state
            break  # ì´ìŠˆëŠ” ìˆì—ˆì§€ë§Œ ì´ë¯¸ ì§ì „ iterationì—ì„œ ìˆ˜ì • ì™„ë£Œ

    # â”€â”€ README ìƒì„± & ìµœì¢… ë¦¬í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n  ğŸ“ README.md ìƒì„± ì¤‘...")
    _generate_readme(state, output_dir, codes)

    final_errors = _run_syntax_checks(output_dir, codes)

    report_lines = ["=== QC ìµœì¢… ë¦¬í¬íŠ¸ ==="]

    if all_issues:
        report_lines.append(f"\në°œê²¬ëœ ì´ìŠˆ ({len(all_issues)}ê±´):")
        for i, issue in enumerate(all_issues, 1):
            report_lines.append(f"  {i}. {issue}")
    else:
        report_lines.append("\nì´ìŠˆ ì—†ìŒ")

    if total_fixed_files:
        report_lines.append(f"\nìë™ ìˆ˜ì •ëœ íŒŒì¼ ({len(total_fixed_files)}ê°œ):")
        for f in sorted(total_fixed_files):
            report_lines.append(f"  - {f}")

    if final_errors:
        report_lines.append(f"\nâš ï¸  ì”ì—¬ ì˜¤ë¥˜ ({len(final_errors)}ê±´):")
        for err in final_errors:
            report_lines.append(f"  {err}")
    else:
        report_lines.append("\nâœ… ìµœì¢… ë¬¸ë²• ê²€ì‚¬ í†µê³¼")

    state.update({
        "codes": codes,
        "feedback": "\n".join(report_lines),
        "current_step": "DONE"
    })
    return state
